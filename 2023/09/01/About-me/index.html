<!DOCTYPE html><html lang="en"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=5"><title>dingwoai</title><meta name="author" content="dingwoai"><link rel="shortcut icon" href="/img/favicon.png"><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.13.0/css/all.min.css"><meta name="generator" content="Hexo 6.3.0"></head><body><header id="page_header"><div class="header_wrap"><div id="blog_name"><a class="blog_title" id="site-name" href="/">dingwoai</a></div><button class="menus_icon"><div class="navicon"></div></button><ul class="menus_items"><li class="menus_item"><a class="site-page" href="/"> About</a></li></ul></div></header><main id="page_main"><div class="side-card sticky"><div class="card-wrap" itemscope itemtype="http://schema.org/Person"><div class="author-avatar"><img class="avatar-img" src="/img/avatar.jpg" onerror="this.onerror=null;this.src='/img/profile.png'" alt="avatar"></div><div class="author-discrip"><h3>dingwoai</h3><p class="author-bio">Senior Algorithm Expert | Kaggle Master | 个人公众号“我AI”</p></div><div class="author-links"><button class="btn m-social-links">Links</button><ul class="social-links"><li><a class="e-social-link" href="https://scholar.google.com/citations?user=hFkcq3IAAAAJ" target="_blank"><i class="fas fa-graduation-cap" aria-hidden="true"></i><span>Google Scholar</span></a></li></ul></div></div></div><div class="page" itemscope itemtype="http://schema.org/CreativeWork"><h2 class="page-title">About me</h2><article><h2 id="Wenbo-Ding"><a href="#Wenbo-Ding" class="headerlink" title="Wenbo Ding"></a>Wenbo Ding</h2><p>I work currently as the Lead of AD Model (Autonomous Driving Model) Team in SAIC AI Lab (working jointly with IMMotors’ AD Center). Our works mainly focus on:</p>
<ul>
<li>building and deploying a robust perception system;</li>
<li>developing End-to-End driving model;</li>
<li>researching on Vision-Language-Action model;</li>
</ul>
<p>for autonomous driving ranging from level 2 to level 4.</p>
<h3 id="Education"><a href="#Education" class="headerlink" title="Education"></a>Education</h3><p>I hold a Dr. Eng. degree of Fudan University, China.</p>
<ul>
<li>I got my Master degree at TU Darmstadt in Germany and Bachelor degree in Zhejiang University, China.</li>
</ul>
<h3 id="News"><a href="#News" class="headerlink" title="News"></a>News</h3><ul>
<li>2025, we improved End-to-End driving model with scaling law and reinforcement learning.</li>
<li>2024, we deployed End-to-End driving model based on imitation learning.</li>
<li>2024&#x2F;06, <strong>3rd place</strong> of CVPR2024 Occupancy Challenge.</li>
<li>2023&#x2F;08, we release Vision-based City NOA in Shanghai. Hightlights: BEV, no HD Map, Occupancy.  <a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s/YeX2U6yX__q3i5qHivZk4A">Demo</a></li>
<li>2023, <strong>BEVFusion4D: Learning LiDAR-Camera Fusion Under Bird’s-Eye-View via Cross-Modality Guidance and Temporal Aggregation</strong>. <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2303.17099">preprint</a></li>
<li>2023&#x2F;03&#x2F;25, our BEVFusion4D method reached <strong>1st place</strong> on both mAP and NDS in nuScenes detection task. </li>
<li>2022, <strong>Consistent Attack: Universal Adversarial Perturbation on Embodied Vision Navigation</strong>. (PRL 2023). <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2206.05751">preprint</a></li>
<li>2022, <strong>WS-3D-Lane: Weakly Supervised 3D Lane Detection With 2D Lane Labels.</strong> (ICRA 2023 accepted). <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2209.11523">preprint</a></li>
<li>2022, <strong>Understanding the Robustness of 3D Object Detection with Bird’s-Eye-View Representations in Autonomous Driving.</strong> (CVPR 2023 accepted). <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2303.17297">preprint</a></li>
<li>2022&#x2F;09&#x2F;07, our DAMEN-T method reached <strong>1st place</strong> in nuScenes camera only tracking task (no external data).</li>
<li>2022&#x2F;08&#x2F;16, our DAMEN (Depth-Augmented CaMEra FusioN) method achieved <strong>3rd place</strong> in nuScenes camera only detection task (no external data).</li>
<li>2019, <strong>solo gold</strong> in Kaggle Open Images 2019 - Object Detection competition and got the reputation of <strong>Kaggle Master</strong>.</li>
<li>2018, <strong>golden prize</strong> in Kaggle Quick, Draw! Doodle Recognition Challenge.</li>
</ul>
<h3 id="Follow-me"><a href="#Follow-me" class="headerlink" title="Follow me"></a>Follow me</h3><p>Follow me if you have WeChat account:</p>
<p align="center">
  <br>
    <img src="/images/qrcode.jpg" width="250" />
  <br>
<p>
</article></div></main><div class="nav-wrap"><div class="nav"><button class="site-nav"><div class="navicon"></div></button><ul class="nav_items"><li class="nav_item"><a class="nav-page" href="/"> About</a></li></ul></div><div class="cd-top"><i class="fa fa-arrow-up" aria-hidden="true"></i></div></div><footer id="page_footer"><div class="footer_wrap"><div class="copyright">&copy;2020 - 2025 by dingwoai</div><div class="theme-info">Powered by <a target="_blank" href="https://hexo.io" rel="nofollow noopener">Hexo</a> & <a target="_blank" href="https://github.com/PhosphorW/hexo-theme-academia" rel="nofollow noopener">Academia Theme</a></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/jquery-pjax@latest/jquery.pjax.min.js"></script><script src="/js/main.js"></script></body></html>